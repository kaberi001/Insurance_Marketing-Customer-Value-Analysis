{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "from scipy.stats import probplot\n",
    "from sklearn.ensemble import BaggingRegressor,RandomForestRegressor,AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import zscore\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "from scipy.stats import ttest_1samp\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import statsmodels.api         as     sm\n",
    "from   statsmodels.formula.api import ols\n",
    "from   statsmodels.stats.anova import anova_lm \n",
    "from scipy.stats import f_oneway, kruskal, mannwhitneyu , levene, ttest_ind\n",
    "from pingouin import welch_anova\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import sklearn.preprocessing as sp\n",
    "import statsmodels.stats.outliers_influence as smof\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.tsa.api as smt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso, Ridge, LassoCV, RidgeCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict,StratifiedKFold\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as gbm\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import BaggingRegressor,RandomForestRegressor,AdaBoostRegressor,VotingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Coverage', 'Education', 'EmploymentStatus', 'Income', 'Marital Status',\n",
       "       'Months Since Last Claim', 'Months Since Policy Inception',\n",
       "       'Number of Open Complaints', 'Number of Policies', 'Renew Offer Type',\n",
       "       'Vehicle Class', 'Vehicle Size', 'Monthly Premium Auto_boxcox',\n",
       "       'Total Claim Amount_boxcox'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data1=pd.read_csv('Insurance data for model building Final.csv')\n",
    "data1.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "X=data1.drop(['Customer Lifetime Value_boxcox'],axis=1)\n",
    "y=data1['Customer Lifetime Value_boxcox']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now initialize Models with best params found from grid search cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.ensemble import GradientBoostingRegressor'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DT=DecisionTreeRegressor(random_state=0,max_depth=18, min_samples_leaf= 5, min_samples_split=14)\n",
    "knn=KNeighborsRegressor(n_neighbors=19, weights='distance')\n",
    "GBR=GradientBoostingRegressor(n_estimators=49,random_state=0)\n",
    "lgb=LGBMRegressor(learning_rate= 0.3,max_depth= 6,min_child_weight= 4,n_estimators= 50,random_state=0)\n",
    "VR = VotingRegressor(estimators=[('LGBM', lgb), ('DT', DT), ('knn', knn),('GBR',GBR)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Test Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the X_train and y_train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingRegressor(estimators=[('LGBM',\n",
       "                             LGBMRegressor(boosting_type='gbdt',\n",
       "                                           class_weight=None,\n",
       "                                           colsample_bytree=1.0,\n",
       "                                           importance_type='split',\n",
       "                                           learning_rate=0.3, max_depth=6,\n",
       "                                           min_child_samples=20,\n",
       "                                           min_child_weight=4,\n",
       "                                           min_split_gain=0.0, n_estimators=50,\n",
       "                                           n_jobs=-1, num_leaves=31,\n",
       "                                           objective=None, random_state=0,\n",
       "                                           reg_alpha=0.0, reg_lambda=0.0,\n",
       "                                           silent=True, subsample=1.0,\n",
       "                                           su...\n",
       "                                                       loss='ls', max_depth=3,\n",
       "                                                       max_features=None,\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=1,\n",
       "                                                       min_samples_split=2,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=49,\n",
       "                                                       n_iter_no_change=None,\n",
       "                                                       presort='deprecated',\n",
       "                                                       random_state=0,\n",
       "                                                       subsample=1.0,\n",
       "                                                       tol=0.0001,\n",
       "                                                       validation_fraction=0.1,\n",
       "                                                       verbose=0,\n",
       "                                                       warm_start=False))],\n",
       "                n_jobs=None, weights=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT.fit(X_train,y_train)\n",
    "knn.fit(X_train,y_train)\n",
    "GBR.fit(X_train,y_train)\n",
    "#xgbr.fit(X_train,y_train)\n",
    "lgb.fit(X_train,y_train)\n",
    "VR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify R2 value for both train and test data for all models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT--->\n",
      "r2_train_score:0.9713286790055831\n",
      "r2_test_score:0.9254036070628732\n"
     ]
    }
   ],
   "source": [
    "print('DT--->')\n",
    "print(f'r2_train_score:{DT.score(X_train,y_train)}')\n",
    "print(f'r2_test_score:{DT.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree MSError 6.788066560433926e-05\n"
     ]
    }
   ],
   "source": [
    "print('Decision Tree MSError', np.mean((DT.predict(X_test) - y_test) ** 2))\n",
    "DT.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSError when predicting the mean 0.0009099977753021909\n"
     ]
    }
   ],
   "source": [
    "print('MSError when predicting the mean', np.mean((y_train.mean() - y_test) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Root Mean Squared Error: 0.008238972363367852\n",
    "Mean Absolute Error: 0.06273343828154825 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on R2 obtained on the model, the performance is nearly same  for train and test data, but still could be a slight overfitting problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn-->\n",
      "r2_train_score:1.0\n",
      "r2_test_score:0.13142332769434795\n"
     ]
    }
   ],
   "source": [
    "print('knn-->')\n",
    "print(f'r2_train_score:{knn.score(X_train,y_train)}')\n",
    "print(f'r2_test_score:{knn.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on R2 obtained on the model, there is very much overfitting problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBR-->\n",
      "r2_train_score:0.9433592057686394\n",
      "r2_test_score:0.940933781762101\n"
     ]
    }
   ],
   "source": [
    "print('GBR-->')\n",
    "print(f'r2_train_score:{GBR.score(X_train,y_train)}')\n",
    "print(f'r2_test_score:{GBR.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on R2 obtained on the model,No overfitting problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgm-->\n",
      "r2_train_score:0.9675021967007211\n",
      "r2_test_score:0.9439839758823547\n"
     ]
    }
   ],
   "source": [
    "print('lightgm-->')\n",
    "print(f'r2_train_score:{lgb.score(X_train,y_train)}')\n",
    "print(f'r2_test_score:{lgb.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions for each model\n",
    "#### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT\n",
      "R2 Squared: 0.9254036070628732\n",
      "Root Mean Squared Error: 0.008238972363367852\n",
      "Mean Absolute Error: 0.06273343828154825 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_DT = DT.predict(X_test)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_GBR = GBR.predict(X_test)\n",
    "print('DT')\n",
    "print ( \"R2 Squared:\" , r2_score ( y_test , y_pred_DT ) )\n",
    "print ( \"Root Mean Squared Error:\" , np.sqrt ( mean_squared_error ( y_test , y_pred_DT ) ) )\n",
    "print ( \"Mean Absolute Error:\" , np.sqrt ( mean_absolute_error ( y_test , y_pred_DT ) ), '\\n' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBR\n",
      "R2 Squared: 0.940933781762101\n",
      "Root Mean Squared Error: 0.00733134597642363\n",
      "Mean Absolute Error: 0.06393690668320526 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_GBR = GBR.predict(X_test)\n",
    "print('GBR')\n",
    "print ( \"R2 Squared:\" , r2_score ( y_test , y_pred_GBR ) )\n",
    "print ( \"Root Mean Squared Error:\" , np.sqrt ( mean_squared_error ( y_test , y_pred_GBR ) ) )\n",
    "print ( \"Mean Absolute Error:\" , np.sqrt ( mean_absolute_error ( y_test , y_pred_GBR ) ), '\\n' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "R2 Squared: 0.13142332769434795\n",
      "Root Mean Squared Error: 0.02811371336786073\n",
      "Mean Absolute Error: 0.14456843193121666 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score , mean_squared_error , mean_absolute_error\n",
    "\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "print('KNN')\n",
    "print ( \"R2 Squared:\" , r2_score ( y_test , y_pred_knn ) )\n",
    "print ( \"Root Mean Squared Error:\" , np.sqrt ( mean_squared_error ( y_test , y_pred_knn ) ) )\n",
    "print ( \"Mean Absolute Error:\" , np.sqrt ( mean_absolute_error ( y_test , y_pred_knn ) ), '\\n' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_train_score:0.2988946229723908\n",
      "r2_test_score:0.2984413632519747\n",
      "LR\n",
      "R2 Squared: 0.2984413632519747\n",
      "Root Mean Squared Error: 0.025266560138643535\n",
      "Mean Absolute Error: 0.1428290440072116 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR=LinearRegression()\n",
    "LR.fit(X_train,y_train)\n",
    "print(f'r2_train_score:{LR.score(X_train,y_train)}')\n",
    "print(f'r2_test_score:{LR.score(X_test,y_test)}')\n",
    "\n",
    "y_pred_LR = LR.predict(X_test)\n",
    "\n",
    "print('LR')\n",
    "print ( \"R2 Squared:\" , r2_score ( y_test , y_pred_LR ) )\n",
    "print ( \"Root Mean Squared Error:\" , np.sqrt ( mean_squared_error ( y_test , y_pred_LR ) ) )\n",
    "print ( \"Mean Absolute Error:\" , np.sqrt ( mean_absolute_error ( y_test , y_pred_LR ) ), '\\n' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM\n",
      "R2 Squared: 0.9439839758823547\n",
      "Root Mean Squared Error: 0.0071395406771122645\n",
      "Mean Absolute Error: 0.06248736514722559 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_lgb = lgb.predict(X_test)\n",
    "\n",
    "print('LightGBM')\n",
    "print ( \"R2 Squared:\" , r2_score ( y_test , y_pred_lgb ) )\n",
    "print ( \"Root Mean Squared Error:\" , np.sqrt ( mean_squared_error ( y_test , y_pred_lgb ) ) )\n",
    "print ( \"Mean Absolute Error:\" , np.sqrt ( mean_absolute_error ( y_test , y_pred_lgb ) ), '\\n' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VotingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Regressor--->\n",
      "R2 Squared: 0.895557213001207\n",
      "r2_train_score:0.981591540410821\n",
      "r2_test_score:0.8955572130012072\n",
      "Root Mean Squared Error: 0.009748849326843811\n",
      "Mean Absolute Error: 0.08010097051768478 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_vr=VR.predict(X_test)\n",
    "print('Voting Regressor--->')\n",
    "print ( \"R2 Squared:\" , r2_score ( y_test , y_pred_vr ) )\n",
    "print(f'r2_train_score:{VR.score(X_train,y_train)}')\n",
    "print(f'r2_test_score:{VR.score(X_test,y_test)}')\n",
    "print ( \"Root Mean Squared Error:\" , np.sqrt ( mean_squared_error ( y_test , y_pred_vr ) ) )\n",
    "print ( \"Mean Absolute Error:\" , np.sqrt ( mean_absolute_error ( y_test , y_pred_vr ) ), '\\n' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Models for latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=LinearRegression()\n",
    "RF=RandomForestRegressor(random_state=0)\n",
    "ABR = AdaBoostRegressor(random_state=0)\n",
    "AB_RF = AdaBoostRegressor(base_estimator=RF, random_state=0)\n",
    "AB_DT = AdaBoostRegressor(random_state=0)\n",
    "xgbr=XGBRegressor(random_state=0)\n",
    "LR.fit(X_train,y_train)\n",
    "\n",
    "RF.fit(X_train,y_train)\n",
    "ABR.fit(X_train,y_train)\n",
    "AB_RF.fit(X_train,y_train)\n",
    "AB_DT.fit(X_train,y_train)\n",
    "print(f'r2_train_score:{LR.score(X_train,y_train)}')\n",
    "print(f'r2_test_score:{LR.score(X_test,y_test)}')\n",
    "print(f'r2_train_score:{ABR.score(X_train,y_train)}')\n",
    "print(f'r2_test_score:{ABR.score(X_test,y_test)}')\n",
    "\n",
    "print(f'r2_train_score:{ABR_DT.score(X_train,y_train)}')\n",
    "print(f'r2_test_score:{ABR_DT.score(X_test,y_test)}')\n",
    "\n",
    "print(f'r2_train_score:{ABR_RF.score(X_train,y_train)}')\n",
    "print(f'r2_test_score:{ABR_RF.score(X_test,y_test)}')\n",
    "\n",
    "print(f'r2_train_score:{xgbr.score(X_train,y_train)}')\n",
    "print(f'r2_test_score:{xgbr.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_LR = LR.predict(X_test)\n",
    "\n",
    "y_pred_ABR = ABR.predict(X_test)\n",
    "y_pred_ABR_DT = ABR_DT.predict(X_test)\n",
    "y_pred_ABR_RF = ABR_RF.predict(X_test)\n",
    "\n",
    "y_pred_xgbr = xgbr.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
